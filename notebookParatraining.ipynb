{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "import numpy as np\n",
    "from config import Config\n",
    "from psgan import Generator, Discriminator\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "config = Config() # Initialize configuration of NN\n",
    "generator = Generator(config)\n",
    "discriminator = Discriminator(config) # Initialize generator and discriminator models\n",
    "\n",
    "gen_optimizer = Adam(learning_rate=config.lr, beta_1=config.b1) # Initialize both optimiizers\n",
    "disc_optimizer = Adam(learning_rate=config.lr, beta_1=config.b1) # Keep separate due to two diff objective functions\n",
    "\n",
    "bce_loss = BinaryCrossentropy(from_logits=True) # from_logits for more stablity w sigmoid\n",
    "\n",
    "# Updated noise sampling\n",
    "def generate_noise(batch_size, nz_local, nz_periodic, zx):\n",
    "    Z = np.zeros((batch_size, nz_local + 2 * nz_periodic, zx, zx))  # No global maps\n",
    "\n",
    "    # Local maps\n",
    "    Z[:, :nz_local] = np.random.uniform(-1., 1., (batch_size, nz_local, zx, zx))\n",
    "\n",
    "    # Periodic maps\n",
    "    for i in range(1, nz_periodic + 1):\n",
    "        freq = np.pi * (0.5 * i / nz_periodic + 0.5)\n",
    "        for h in range(zx):\n",
    "            Z[:, nz_local + 2 * (i - 1), :, h] = h * freq  # Horizontal sine wave\n",
    "        for w in range(zx):\n",
    "            Z[:, nz_local + 2 * (i - 1) + 1, w, :] = w * freq  # Vertical cosine wave\n",
    "    return tf.convert_to_tensor(Z, dtype=tf.float32)\n",
    "\n",
    "\n",
    "def save_generated_images(images, epoch, samples_dir='samples_chequered'):\n",
    "    images = (images + 1.0) * 127.5\n",
    "    images = tf.clip_by_value(images, 0, 255).numpy().astype(np.uint8)\n",
    "    os.makedirs(samples_dir, exist_ok=True)\n",
    "    for i, img in enumerate(images[:5]):\n",
    "        tf.keras.preprocessing.image.save_img(\n",
    "            f\"{samples_dir}/generated_epoch_{epoch + 1}_img_{i + 1}.png\", img\n",
    "        )\n",
    "\n",
    "fixed_noise = generate_noise(1, config.nz_local, config.nz_periodic, config.zx_sample) # Generate noise\n",
    "\n",
    "os.makedirs('samples_chequered', exist_ok=True) # Create directory to write stuff to to reuse\n",
    "os.makedirs('models_chequered', exist_ok=True)\n",
    "\n",
    "@tf.function\n",
    "def train_step(real_images):\n",
    "    '''\n",
    "    Perform one training step for PSGAN, which entails:\n",
    "    1) Updating the discriminator.\n",
    "    2) Updating the generator.\n",
    "    '''\n",
    "    noise = generate_noise(config.batch_size, config.nz_local, config.nz_periodic, config.zx) # Make noise\n",
    "    print(f\"Noise Shape: {tf.shape(noise)}\")\n",
    "\n",
    "    # Update discriminator\n",
    "    with tf.GradientTape() as gg:\n",
    "        gen_images = generator(noise, training=True)\n",
    "        real_output = discriminator(real_images, training=True) # Check discernment\n",
    "        fake_output = discriminator(gen_images, training=True)\n",
    "\n",
    "        real_loss = bce_loss(tf.ones_like(real_output), real_output)\n",
    "        fake_loss = bce_loss(tf.zeros_like(fake_output), fake_output) # Real: 1s, fake: 0s\n",
    "        disc_loss = real_loss + fake_loss \n",
    "\n",
    "    disc_grads = gg.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    disc_optimizer.apply_gradients(zip(disc_grads, discriminator.trainable_variables))\n",
    "\n",
    "    # Update generator\n",
    "    with tf.GradientTape() as dg:\n",
    "        gen_images = generator(noise, training=True)\n",
    "        fake_output = discriminator(gen_images, training=True)\n",
    "        gen_loss = bce_loss(tf.ones_like(fake_output), fake_output) # Generator wins if discriminator says its real\n",
    "\n",
    "    gen_grads = dg.gradient(gen_loss, generator.trainable_variables)\n",
    "    gen_optimizer.apply_gradients(zip(gen_grads, generator.trainable_variables))\n",
    "    return gen_loss, disc_loss \n",
    "\n",
    "def train(dataset, epochs):\n",
    "    '''\n",
    "    Train PSGAN model for given # of epochs\n",
    "    '''\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        gen_losses = []\n",
    "        disc_losses = []\n",
    "        for step, real_images in enumerate(dataset):\n",
    "            gen_loss, disc_loss = train_step(real_images) # Go through dataset\n",
    "            gen_losses.append(gen_loss); disc_losses.append(disc_loss)\n",
    "            if step % 100 == 0:\n",
    "                print(f\"Step {step}: Generator Loss: {gen_loss:.4f}, Disciminator loss: {disc_loss:.4f}\")\n",
    "        gen_images = generator(fixed_noise, training=False)\n",
    "        save_generated_images(gen_images, epoch)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0: # Save model weights per 10th iteration\n",
    "            generator.save_weights(f\"models/generator_epoch_{epoch + 1}.weights.h5\")\n",
    "            discriminator.save_weights(f\"models/discriminator_epoch_{epoch + 1}.weights.h5\")\n",
    "\n",
    "def load_and_preprocess_images(image_dir, target_size=(128, 128), batch_size=25):\n",
    "    \"\"\"\n",
    "    Load images from a directory, resize to target size, normalize to [-1, 1], and batch them.\n",
    "    Inputs:\n",
    "        image_dir (str): Path to the directory containing images.\n",
    "        target_size (tuple): Target size for the images (height, width). For our nn, do 161x161 this is specified.\n",
    "        batch_size (int): Batch size for loading.\n",
    "        \n",
    "    Outputs:\n",
    "        Dataset, A TensorFlow dataset of preprocessed images.\n",
    "    \"\"\"\n",
    "    # Load and resize images from directory\n",
    "    dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "        image_dir,\n",
    "        label_mode=None, # No label needed for GAN\n",
    "        image_size=target_size,  \n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    # Normalize between -1 and 1\n",
    "    dataset = dataset.map(lambda x: (x / 127.5) - 1.0, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    # Prefetching improves performance\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "def visualize_dataset_images(dataset, num_images=5):\n",
    "    \"\"\"\n",
    "    Visualize a batch of images from the dataset.\n",
    "    Inputs:\n",
    "        dataset: TensorFlow dataset of images.\n",
    "        num_images: Number of images to display.\n",
    "    \"\"\"\n",
    "    # Extract one batch of images\n",
    "    for images in dataset.take(1):\n",
    "        images = (images + 1.0) / 2.0  # Rescale from [-1, 1] to [0, 1]\n",
    "        images = tf.clip_by_value(images, 0.0, 1.0)  # Ensure no values outside [0, 1]\n",
    "        \n",
    "        plt.figure(figsize=(15, 5))\n",
    "        for i in range(num_images):\n",
    "            plt.subplot(1, num_images, i + 1)\n",
    "            plt.imshow(images[i].numpy())\n",
    "            plt.axis(\"off\")\n",
    "            plt.title(f\"Image {i+1}\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicate images into new folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated the image 120 times in the folder 'curatedHoneycomb'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Input image path (relative path)\n",
    "input_image_path = \"dtd_folder/dtd/images/honeycombed/honeycombed_0003.jpg\"  # Replace with your image path\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"curatedHoneycomb\"\n",
    "os.makedirs(output_dir, exist_ok=True)  # Create the folder if it doesn't exist\n",
    "\n",
    "# Number of duplicates\n",
    "num_duplicates = 120\n",
    "\n",
    "# Loop to create duplicates with unique filenames\n",
    "for i in range(1, num_duplicates + 1):\n",
    "    output_file = os.path.join(output_dir, f\"honeycomb_{i}.jpg\")\n",
    "    shutil.copy(input_image_path, output_file)\n",
    "\n",
    "print(f\"Duplicated the image {num_duplicates} times in the folder '{output_dir}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images!\n",
      "Found 120 files.\n",
      "Starting PSGAN training...wish me luck\n",
      "Epoch 1/100\n",
      "Noise Shape: Tensor(\"Shape:0\", shape=(4,), dtype=int32)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\ASC_Student\\AppData\\Local\\Temp\\ipykernel_10204\\3484568269.py\", line 63, in train_step  *\n        gen_images = generator(noise, training=True)\n    File \"C:\\Users\\ASC_Student\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\inspect.py\", line 3195, in bind\n        return self._bind(args, kwargs)\n    File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\inspect.py\", line 3110, in _bind\n        raise TypeError(msg) from None\n\n    TypeError: missing a required argument: 'random_phases'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m dataset \u001b[38;5;241m=\u001b[39m load_and_preprocess_images(images_dir, target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m), batch_size\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mbatch_size)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting PSGAN training...wish me luck\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_count\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining complete! Check \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msamples/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for generated images and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for saved models.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 93\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(dataset, epochs)\u001b[0m\n\u001b[0;32m     91\u001b[0m disc_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, real_images \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataset):\n\u001b[1;32m---> 93\u001b[0m     gen_loss, disc_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal_images\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Go through dataset\u001b[39;00m\n\u001b[0;32m     94\u001b[0m     gen_losses\u001b[38;5;241m.\u001b[39mappend(gen_loss); disc_losses\u001b[38;5;241m.\u001b[39mappend(disc_loss)\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\Users\\ASC_ST~1\\AppData\\Local\\Temp\\__autograph_generated_file0ckqrb55.py:18\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_step\u001b[1;34m(real_images)\u001b[0m\n\u001b[0;32m     16\u001b[0m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mprint\u001b[39m)(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNoise Shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mshape,\u001b[38;5;250m \u001b[39m(ag__\u001b[38;5;241m.\u001b[39mld(noise),),\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\u001b[38;5;250m \u001b[39mfscope)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m gg:\n\u001b[1;32m---> 18\u001b[0m     gen_images \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     real_output \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(discriminator), (ag__\u001b[38;5;241m.\u001b[39mld(real_images),), \u001b[38;5;28mdict\u001b[39m(training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), fscope)\n\u001b[0;32m     20\u001b[0m     fake_output \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(discriminator), (ag__\u001b[38;5;241m.\u001b[39mld(gen_images),), \u001b[38;5;28mdict\u001b[39m(training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), fscope)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\inspect.py:3195\u001b[0m, in \u001b[0;36mSignature.bind\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   3191\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[0;32m   3192\u001b[0m \u001b[38;5;124;03m    and `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[0;32m   3193\u001b[0m \u001b[38;5;124;03m    if the passed arguments can not be bound.\u001b[39;00m\n\u001b[0;32m   3194\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3195\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\inspect.py:3110\u001b[0m, in \u001b[0;36mSignature._bind\u001b[1;34m(self, args, kwargs, partial)\u001b[0m\n\u001b[0;32m   3108\u001b[0m                 msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing a required argument: \u001b[39m\u001b[38;5;132;01m{arg!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   3109\u001b[0m                 msg \u001b[38;5;241m=\u001b[39m msg\u001b[38;5;241m.\u001b[39mformat(arg\u001b[38;5;241m=\u001b[39mparam\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m-> 3110\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3111\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3112\u001b[0m     \u001b[38;5;66;03m# We have a positional argument to process\u001b[39;00m\n\u001b[0;32m   3113\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n    File \"C:\\Users\\ASC_Student\\AppData\\Local\\Temp\\ipykernel_10204\\3484568269.py\", line 63, in train_step  *\n        gen_images = generator(noise, training=True)\n    File \"C:\\Users\\ASC_Student\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\inspect.py\", line 3195, in bind\n        return self._bind(args, kwargs)\n    File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\inspect.py\", line 3110, in _bind\n        raise TypeError(msg) from None\n\n    TypeError: missing a required argument: 'random_phases'\n"
     ]
    }
   ],
   "source": [
    "images_dir = 'C:/Users/ASC_Student/Documents/GitHub/GAN-Texture-Synthesis/dtd_folder/dtd/images/curatedHoneycomb'\n",
    "print(\"Loading images!\")\n",
    "dataset = load_and_preprocess_images(images_dir, target_size=(128, 128), batch_size=config.batch_size)\n",
    "\n",
    "print(\"Starting PSGAN training...wish me luck\")\n",
    "train(dataset, epochs=config.epoch_count)\n",
    "print(\"Training complete! Check 'samples/' for generated images and 'models/' for saved models.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
